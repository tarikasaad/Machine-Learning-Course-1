MODELS (Lin, Polynomial, DecTreeReg, DecTreeClass, Bagged_tree, RF)
GENERAL STEPS FOR MODELS:
1) Load data, split into X and Y and reshape them into 2D arrays
2) Use traintestsplit to split X and Y into training and testing data
3) Define your model (either make_polynomial or DecisionTreeRegressor/Classifier etc)
4) Fit your model to training set
5) Define MSE
6) Define X_seq by using np.linspace 
7) plot the scatterplot, plot the prediction on x_seq and find mse on xtest ytest


data = pd.read_csv('xyz.csv')
x = np.array(data['feature1'])
y = np.array(data['feature2'])

x = seq.reshape(-1,1)
y = seq.reshape(-1,1)
X_seq = np.linspace(0,100,10000)

def MSE(polyreg, X, Y):
	return ((y - model.predict(X))**2).mean()

###model = make_pipeline(PolyFeatures(deg = x), LinReg())
###tree_reg = DecTreeReg(min_split_samples = x)
###tree_classifier = DecisionTreeClassifier(max_leaf_nodes=3, criterion="entropy",max_depth=2) ###Max depth is the length from root node to leaf
                                                                                               ###Increasing max depth leads to overfitting
###tree_classifier.fit(X,y)
###tree.plot_tree(tree_classifier)
###tree.plot_tree(tree_classifier, max_depth=3)
###bagged_regression_tree = BaggingRegressor(base_estimator=DecisionTreeRegressor(max_leaf_nodes=max_leaf), n_estimators = 500)
###rf = RandomForestRegressor(n_estimators=500, oob_score=True, max_features="sqrt")

X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size = n, r.s. = 5)

model.fit(X_train, Y_train)
print('The mse is:', MSE(model, X_test, Y_test)

plt.scatter(X,Y, color = 'blue')
plt.plot(X_seq, model.predict(X_seq), color = 'black')
plt.show()


-------------------------------------------------------------------------------------------------------------------------------------------
SVC
GENERAL STEPS FOR SVC:
1) Create clusters of X
2) Combine x define y
3) Create SVC object
4) Fit to X,Y and plot model plt(SVC,X,Y)

1) Create 2 clusters of x
mean1 = [1,1]
cov1 = [[0,1],[1,0]]
x_clust1 = np.random.multivariate_normal(mean1,cov1,rs)

repeat for cluster 2

2) Combine x and define y
X = np.append(xcluster1, xcluster2, axis = 0)
y = np.repeat([1,-1],10), so xcluster1 which is column 0, gets label 1 and xcluster2 gets label -1

3) create svc object
svc1 = SVC

-------------------------------------------------------------------------------------------------------------------------------------------------
Probabilistic Predictions:
1) Process the data by changing all the yes votes of the binary questions to a probability, (%/100) 
2)Those that have no data, fill them in with the value of 50 (or 0.5)
3)Define the outcome variable, which is a vector with 1s and 0s that represent the correct outcome of 1 or 0 
4) Define the functions for QSR and LSR.

def qsr(x,y)
	return (1-(y-x)^2)

def lsr(x,y):
	if x == 1:
		return np.log(y)
	elif x == 0:
		return np.log(1-y)








-------------------------------------------------------------------------------------------------------------------------------------------

tree_classifier = DecisionTreeClassifier(max_leaf_nodes=3, criterion="entropy",max_depth=2)
tree_classifier.fit(X,y)
tree.plot_tree(tree_classifier)
#tree.plot_tree(tree_classifier, max_depth=3)
